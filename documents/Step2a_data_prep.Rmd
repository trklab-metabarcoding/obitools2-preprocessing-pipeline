---
title: "Step 2a - data preparation"
author: "T. Divoll"
date: "2023-09-12"
output: 
  html_document:
  df_print: paged
  toc: true
---

```{r setup, include=FALSE}
# set global chunk parameters here
knitr::opts_chunk$set(echo = TRUE)
here::i_am("documents/Step2a_data_prep.Rmd")
```

## Environment Setup

This notebook can be used to run the OBITools 3 pipeline and serve as a tutorial. Run through each code chunk and inspect the outputs or select Run All from the dropdown above to run the whole pipeline. First, update the parameters in the first code chunk.

```{r include=FALSE}
#install.packages("pacman")
pacman::p_load(here, tidyverse, readxl, Biostrings, stringr)
```

#### Update parameters and thresholds
```{r}
cutadapt_mismatch <- 2 # -e in cutadapt
min_read_count <- 1000
min_read_length <- # -l in obigrep
max_read_length <- # -L in obigrep
clean_threshold <- 0.05 # -r in obiclean
F_primer <- DNAString("GGGCAATCCTGAGCCAA")
R_primer <- DNAString("CCATTGAGTCTCTGCACCTATC")
```

#### Set up standard path variables
```{r}
samples_dir <- here("data")
output_dir <- here("results")
batch_file_list <- list.files(samples_dir, full.names=T, pattern="xlsx")
sample_sheet <- read_xlsx(here("data/sample_sheet_test.xlsx"), col_types = "guess")
sample_sheet_metadata <- read_xlsx(here("data/sample_sheet_test_metadata.xlsx"), col_types = "guess")
Sys.setenv(samples_dir=samples_dir)
```

#### Generate some additional parameters from inputs
```{r}
reverseComplement(F_primer)
reverseComplement(R_primer)
```
The following dates are pulled from the sample sheet and can be used to filter out dates in case of contamination. The unique extraction, PCR, and sequencing dates are cast to lists that we can then index into later.
```{r}
extraction_date <- as.list(unique(sample_sheet$`Ext date`))
pcr_date <- as.list(unique(sample_sheet$`PCR date`))
sequencing_date <- as.list(unique(sample_sheet$`seq date`))
```

#### Rename files with project-specific sample names
We can make a list of the existing fasta.gz files, and then use column pairings with lab and field sample names to update the file names.

```{r}
file_names_original <- list.files(samples_dir, pattern=".gz", full.names = T) 
lab_name <- sample_sheet$SampleName
field_name <- sample_sheet$SampleID
df <- data.frame(field_name, lab_name)
file_names <- stringr::str_replace_all(file_names_original, setNames(df$field_name, df$lab_name))
file_names <- stringr::str_replace(file_names, "_S\\d+_L001", "")
file.rename(file_names_original, file_names)
```

#### Trim primers with cutadapt
This section will strip off the primers and send the "stdout" to a file so we can keep track of what was removed for each sample.
```{r}
sampleNames <- as.list(field_name)
```

**NOTE** At this point, the code chunks switch over from R to Bash
```{bash}
for sample in $(cat sampleNames)
do

    echo "On sample: $sample"
    
    cutadapt -a ^GGGCAATCCTGAGCCAA...GATAGGTGCAGAGACTCAATGG -A ^CCATTGAGTCTCTGCACCTATC...TTGGCTCAGGATTGCCC --no-indels -e $cutadapt_mismatch --discard-untrimmed -o ${sample}_R1_001_trimmed.fastq.gz -p ${sample}_R2_001_trimmed.fastq.gz ${sample}_R1_001.fastq.gz ${sample}_R2_001.fastq.gz >> cutadapt_primer_trimming_stats.txt 2>&1
done
```

Now look at what fraction of reads were retained in each sample (column 2) and what fraction of bps were retained in each sample (column 3). Expect ~95%+ of reads to be retained and ~50-70% of bps. 
```{bash}
paste sampleNames <(grep "passing" cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") <(grep "filtered" cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")")
```

