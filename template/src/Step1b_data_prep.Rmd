---
title: "Step 1b - data preparation"
subtitle: "Run quality control checks on raw sequence data and trim primers from forward and reverse reads."
author: "T. Divoll"
date: "2023-09-12"
output: 
  html_document:
  df_print: paged
  toc: true
params: 
    #don't change these
    user: !r Sys.getenv("LOGNAME")
    data_path: "/oscar/data/tkartzin/projects"
  
    #do change params below this line as needed
    project_code: "test"
    
    ##cutadapt params
    primer_mismatch: 3
    F_primer: "GGGCAATCCTGAGCCAA" # forward primer used in PCR (or you are interested in using, excluding Nextera overhang)
    R_primer: "CCATTGAGTCTCTGCACCTATC" # reverse primer used in PCR (or you are interested in using, excluding Nextera overhang)
---

This notebook can be used to run the OBITools 1.2.12 pipeline and serve as a tutorial. Run through each code chunk and inspect the outputs.

```{r include=FALSE}
## Only needed for knitr to render this notebook
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, readxl, stringr, spgs, filesstrings)
here::i_am("./Step1b_data_prep.Rmd")
```

```{r setup, include=FALSE}
# set global chunk parameters here
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
do.call('Sys.setenv', params)
```

#### Generate some derived parameters from the inputs
```{r}
F_primer_reverse <- reverseComplement(params$F_primer)
R_primer_reverse <- reverseComplement(params$R_primer)
F_primer_reverse 
R_primer_reverse
```

```{r}
## make environment variables that can be passed to bash code chunks
Sys.setenv(user=params$user)
Sys.setenv(F_primer=params$F_primer)
Sys.setenv(R_primer=params$R_primer)
Sys.setenv(F_primer_reverse = F_primer_reverse)
Sys.setenv(R_primer_reverse = R_primer_reverse)
```

#### Rename files with project-specific sample names
We can make a list of the existing fasta.gz files, and then use column pairings with lab and field sample names to update the file names.

```{r}
file_names_original <- list.files(here("renamed_data"), pattern=".gz", full.names = T, recursive = T)
lab_name <- sample_sheet$SampleName
field_name <- sample_sheet$SampleID
df <- data.frame(field_name, lab_name)
file_names <- stringr::str_replace_all(file_names_original, setNames(df$field_name, df$lab_name))
file.rename(file_names_original, file_names)
```

```{r}
control_samples <- sample_sheet %>% filter(SampleType == "control")
control_samples <- unique(control_samples$SampleID)
```

```{r}
capture.output(control_samples, file = here('results/bad_controls_path/control_list.txt'))
capture.output(file_names, file = here('results/file_names.txt'))
```

#### TODO: Generate FastQC report and plots
```{r}
#dir.create(here("fastqc"))
#fastqc(fq.dir = here("data"), qc.dir = here("fastqc"), threads = 4)

#for (file in seq_along(field_name)) {
#  folder <- dir.create(file.path(here(work_dir, "fastqc", field_name[file])))
  #qckitfastq::run_all(file, folder)

```

#### Trim primers with Cutadapt

This section will strip off the primers and send the "stdout" to a file so we can keep track of what was removed for each sample.

**NOTE** At this point, the code chunks switch over from R to Bash

```{bash, install-cutadapt, eval = FALSE, echo = FALSE}
source ~/.bash_profile

if conda info --envs | grep -q cutadaptenv
then 
  echo "cutadaptenv already exists" 
else 
  conda create -y -n cutadaptenv -c conda-forge -c bioconda cutadapt python=3.9 
fi
```

```{bash}
cd ./renamed_data
ls *_R1_001.fastq.gz | cut -f1 -d "_" > sampleNames
```

```{bash}
cd ./renamed_data
cat sampleNames
```

#### Strip out sample IDs from file names
```{bash}
cd ./renamed_data
for file in *; do
  mv "$file" "`echo $file | sed "s/_[^_]*_/_/"`";
done
```

```{bash}
conda init bash
source ~/.bash_profile
source activate /users/${user}/.conda/envs/cutadaptenv
cd ./renamed_data

for sample in $(cat sampleNames)
do

    echo "On sample: $sample"
  
    cutadapt -a $F_primer...$R_primer_reverse -A $R_primer...$F_primer_reverse --no-indels -e $primer_mismatch --discard-untrimmed -o ${sample}_L001_R1_001_trimmed.fastq.gz -p ${sample}_L001_R2_001_trimmed.fastq.gz ${sample}_L001_R1_001.fastq.gz ${sample}_L001_R2_001.fastq.gz >> ../results/cutadapt_primer_trimming_stats.txt 2>&1
done

mv *trimmed.fastq.gz ../results
```
Now look at what fraction of reads were retained in each sample (column 2) and what fraction of bps were retained in each sample (column 3). Expect \~95%+ of reads to be retained and \~50-70% of bps.

```{bash}
source ~/.bash_profile
source activate /users/${user}/.conda/envs/cutadaptenv

paste ./renamed_data/sampleNames <(grep "passing" ./results/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") <(grep "filtered" ./results/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") | column -t
```

Deactivate the conda environment that uses Python 3 for Cutadapt

```{bash}
source ~/.bash_profile
source deactivate
```

Now navigate to the notebook `Step1c_data_processing.Rmd` in the Files window pane. All of the variables and parameters should still be available in the R environment (see the `Environment` window pane.)
