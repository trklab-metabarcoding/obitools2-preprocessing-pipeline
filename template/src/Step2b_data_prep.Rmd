---
title: "Step 2b - data preparation"
author: "T. Divoll"
date: "2023-09-12"
output: 
  html_document:
  df_print: paged
  toc: true
---

This notebook can be used to run the OBITools 1.2.12 pipeline and serve as a tutorial. Run through each code chunk and inspect the outputs.

```{r include=FALSE}
## Only needed for knitr to render this notebook
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, readxl, stringr, spgs, filesstrings, fastqcr)
if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("qckitfastq")
here::i_am("./Step2b_data_prep.Rmd")
```

#### Rename files with project-specific sample names

We can make a list of the existing fasta.gz files, and then use column pairings with lab and field sample names to update the file names.

```{r}
file_names_original <- list.files(samples_path, pattern=".gz", full.names = T, recursive = T)
lab_name <- sample_sheet$SampleName
field_name <- sample_sheet$SampleID
df <- data.frame(field_name, lab_name)
file_names <- stringr::str_replace_all(file_names_original, setNames(df$field_name, df$lab_name))
file.rename(file_names_original, file_names)
```

```{r}
control_samples <- sample_sheet %>% filter(SampleType == "control")
control_samples <- unique(control_samples$SampleID)
```

```{r}
capture.output(control_samples, file = here('results/control_list.txt'))
capture.output(file_names, file = here('results/file_names.txt'))
```

#### TODO: Generate FastQC report and plots
```{r}
#dir.create(here("fastqc"))
#fastqc(fq.dir = here("data"), qc.dir = here("fastqc"), threads = 4)

#for (file in seq_along(field_name)) {
#  folder <- dir.create(file.path(here(work_dir, "fastqc", field_name[file])))
  #qckitfastq::run_all(file, folder)

```

#### Trim primers with Cutadapt

This section will strip off the primers and send the "stdout" to a file so we can keep track of what was removed for each sample.

**NOTE** At this point, the code chunks switch over from R to Bash

```{bash, install-cutadapt, eval = FALSE, echo = FALSE}
source ~/.bash_profile

if conda info --envs | grep -q cutadaptenv
then 
  echo "cutadaptenv already exists" 
else 
  conda create -y -n cutadaptenv -c conda-forge -c bioconda cutadapt python=3.9 
fi
```

```{bash}
cd ./data
ls *_R1_001.fastq.gz | cut -f1-2 -d "_" > sampleNames
```

```{bash}
cd ./data
cat sampleNames
```

```{bash}
conda init bash
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/cutadaptenv
cd $samples_path
for sample in $(cat sampleNames)
do

    echo "On sample: $sample"
  
    cutadapt -a ^$F_primer...$R_primer_reverse -A ^$R_primer...$R_primer_reverse --no-indels -e $primer_mismatch --discard-untrimmed -o ${sample}_L001_R1_001_trimmed.fastq.gz -p ${sample}_L001_R2_001_trimmed.fastq.gz ${sample}_L001_R1_001.fastq.gz ${sample}_L001_R2_001.fastq.gz >> ../results/cutadapt_primer_trimming_stats.txt 2>&1
done

mv *trimmed.fastq.gz ../results
```
Now look at what fraction of reads were retained in each sample (column 2) and what fraction of bps were retained in each sample (column 3). Expect \~95%+ of reads to be retained and \~50-70% of bps.

```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/cutadaptenv

paste ./data/sampleNames <(grep "passing" ./results/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") <(grep "filtered" ./results/cutadapt_primer_trimming_stats.txt | cut -f3 -d "(" | tr -d ")") | column -t
```

Deactivate the conda environment that uses Python 3 for Cutadapt

```{bash}
source ~/.bash_profile
conda deactivate
```

Now navigate to the notebook `Step2b_data_processing.Rmd` in the Files window pane. All of the variables and parameters should still be available in the R environment (see the `Environment` window pane.)
