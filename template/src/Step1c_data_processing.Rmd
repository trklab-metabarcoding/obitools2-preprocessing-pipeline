---
title: "Step1c_data_processing"
author: "T. Divoll"
date: "2023-09-12"
output: 
  html_document:
  df_print: paged
  toc: true
params:
    #don't change these
    user: !r Sys.getenv("LOGNAME")
    data_path: "/oscar/data/tkartzin/projects"
  
    #do change params below this line as needed
    project_code: "test"
    todaydate: !r (format(Sys.Date(), "%Y%m%d"))
    
    ##obitools params
    min_read_count: 1000
    min_read_length: 8 # -l in obigrep
    max_read_length: 300 # -L in obigrep
    clean_threshold: 0.05 # -r in obiclean
    matching_score: 40 # --score-min in illuminapairedend
---
```{r include=FALSE}
## Only needed for knitr to render this notebook
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, here, tidyr, dplyr, readxl, stringr, spgs, filesstrings)
here::i_am("./Step1c_data_processing.Rmd")
```

```{r setup, include=FALSE}
# set global chunk parameters here
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
do.call('Sys.setenv', params)
```

#### Set up Conda env for OBITools
```{bash, install obitools, eval = FALSE, echo = FALSE}
source ~/.bash_profile

if conda info --envs | grep -q obitools-env
then 
  echo "obitools-env already exists" 
else 
  conda create -n obitools-env -y -c conda-forge -c bioconda obitools ecoprimers ecopcr python=2.7 
fi
```

#### Merge Illumina forward and reverse reads
```{bash}
#Recover full sequence reads from forward and reverse partial reads using illuminapairedend command in obitools
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results

for sample in $(cat ../renamed_data/sampleNames)
do
    echo "On sample: $sample"
    
    illuminapairedend --score-min=$matching_score -r ${sample}_L001_R2_001_trimmed.fastq.gz ${sample}_L001_R1_001_trimmed.fastq.gz > ${sample}_merged.fastq
    
    obicount ${sample}_merged.fastq
done
```

#### Filter out unaligned reads
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results

for sample in $(cat ../renamed_data/sampleNames)

do
    obigrep -p 'mode!="joined"' ${sample}_merged.fastq > ${sample}_ali.fastq
done | column -t
```

#### Add sample names to each file
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results

for sample in $(cat ../renamed_data/sampleNames)

do
    obiannotate -S sample:${sample} ${sample}_ali.fastq >  ${sample}_id.fastq

done | column -t

mv *_id.fastq ./id_data
```

#### Inspect read counts in fecal samples vs controls
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results/id_data

obistat -c sample *_id.fastq --without-progress-bar | column -t
```

#### Combine remaining sequences into one FASTA and dereplicate
```{bash quiet=TRUE}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results/id_data

obiuniq -m sample *_id.fastq --without-progress-bar > all.uniq.fasta

obicount all.uniq.fasta --without-progress-bar
```

#### Filter results to just `count` and `merged_sample` attributes in FASTA headers
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results/id_data

obiannotate -k count -k merged_sample all.uniq.fasta > $$ ; mv $$ all.uniq.fasta
```

#### Inspect the `count` attribute
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results/id_data

# get the counting statistics on the ‘count’ attribute
{
obistat -c count all.uniq.fasta --without-progress-bar | sort -nk1 | head -20 | column -t 
} | tee -a seq_count_table.txt
```

#### Create a tabulated file for counts per sequence read
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env
cd ./results/id_data

obitab -o all.uniq.fasta > all.uniq.tab
```
#### Read the tab file as a table in R
After running the cell below, open the table from the Environment tab and inspect the results!
```{r}
all_uniq_tab <- read.delim(here("results/id_data/all.uniq.tab"), header=TRUE)
```

Use this space to take notes on the controls that have been looked into. For example, something like this: 
```
BLA20220920.A
6671/17628 (38%) – Glehnia littoralis = American silvertop
3442/5438 (63%) – Musa balbisiana = plantain
```
#### Move all the control samples over to an archive directory
Now that the controls have been looked into, we can move the sample files over to a folder called `control_samples`
```{r}
merged_files <- list.files(here("results/id_data"), pattern="*id.fastq", full.names = T)
```

```{r}
control_files <- merged_files[grepl(paste(control_samples, collapse= "|"), merged_files)]
```

Add all of the `*id.fastq` files you want to move to the list named `bad_samples_to_move`. This will move them to a `bad_controls_samples` folder. These can be from suspected contamination or from low read counts (i.e., < 1000 reads).
```{r}
##EXAMPLE: here("results/id_data", c("YNP218_S1_id.fastq", "YNP297_S13_id.fastq"))

bad_samples_to_move <- here("results/id_data", c("", ""))
```

```{r}
move_files(control_files, here("results/bad_controls_path"), overwrite = FALSE)
move_files(bad_samples_to_move, here("results/bad_controls_path"), overwrite = FALSE)
```

Let's also move this first data set to archive and we will re-run merging and de-replication in the next notebook, without controls and bad samples.
```{r}
move_files(c(here("results/id_data", "all.uniq.fasta"), here("results/id_data", "all.uniq.tab")), here("results/bad_controls_path"), overwrite = FALSE)
```

Create an environment variable for the results destination path.
```{r}
DIR = basename(getwd())
mapped_folder <- 
  filter(seq_date_names, value == DIR)$Folder
Sys.setenv(mapped_folder=mapped_folder)
Sys.setenv(analysis_date=params$todaydate)
```

Copy over your results folder and the Steps 1b and 1c notebooks to the shared lab directory on Oscar.
**Note: Save this notebook first so any results are recorded before copying.**
```{bash}
source ~/.bash_profile
conda activate /users/${user}/.conda/envs/obitools-env

destination=${data_path}/${project_code}/${mapped_folder}/${DIR}/${analysis_date}_${user}
mkdir -p ${destination}
cp -r ./results/id_data ${destination}
cp -r ./results/bad_controls_path ${destination}
cp -r ./renamed_data ${destination}
cp *.Rmd ${destination}
cp ./results/cutadapt_primer_trimming_stats.txt ${destination}

conda deactivate
```

Now navigate to the notebook `Step3a_data_cleaning.Rmd` in the `obitools2-taxonomy-assignment` [repository](https://github.com/trklab-metabarcoding/obitools2-taxonomy-assignment). Use the Files pane in RStudio to navigate to `/oscar/data/tkartzin/r'params$user'/obitools2-taxonomy-assignment`.